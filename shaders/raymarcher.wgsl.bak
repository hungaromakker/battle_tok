// Sketch Engine - Main Ray Marcher Shader
// This shader performs fullscreen ray marching against SDF entities

// ============================================================================
// UNIFORM BINDINGS
// ============================================================================

// Uniforms struct layout (192 bytes total):
// - view_proj:          mat4x4<f32> @ offset 0   (64 bytes)
// - inv_view_proj:      mat4x4<f32> @ offset 64  (64 bytes)
// - camera_pos:         vec3<f32>   @ offset 128 (12 bytes)
// - time:               f32         @ offset 140 (4 bytes)
// - resolution:         vec2<f32>   @ offset 144 (8 bytes)
// - step_count:         u32         @ offset 152 (4 bytes)
// - lod_debug_mode:     u32         @ offset 156 (4 bytes)
// - preview_position:   vec3<f32>   @ offset 160 (12 bytes)
// - preview_sdf_type:   u32         @ offset 172 (4 bytes)
// - preview_enabled:    u32         @ offset 176 (4 bytes)
// - entity_debug_mode:  u32         @ offset 180 (4 bytes) - US-0M04: 0=off, 1=position RGB, 2=count brightness
// - terrain_visible:    u32         @ offset 184 (4 bytes) - US-0N01: 1=visible, 0=hidden (F1 toggle)
// - camera_mode:        u32         @ offset 188 (4 bytes) - US-019: 0=third-person, 1=first-person
// Total: 192 bytes
//
// IMPORTANT: We use separate u32 fields for padding instead of vec3<u32> or array<u32, 3>
// because:
// - vec3<u32> has 16-byte alignment in WGSL, causing a size mismatch (208 vs 192 bytes)
// - array<u32, 3> in uniform buffers requires 16-byte stride alignment
// The Rust struct uses [u32; 2] which has 4-byte alignment, so separate u32 fields match.
struct Uniforms {
    view_proj: mat4x4<f32>,
    inv_view_proj: mat4x4<f32>,  // Inverse view-projection for ray direction calculation
    camera_pos: vec3<f32>,
    time: f32,
    resolution: vec2<f32>,
    step_count: u32,
    lod_debug_mode: u32,  // 1 = enabled, 0 = disabled (also used for SDF debug modes 2-7)
    preview_position: vec3<f32>,  // World-space position for placement preview
    preview_sdf_type: u32,        // SDF type for preview (0 = sphere, 1 = box, 2 = capsule)
    preview_enabled: u32,         // Whether preview is enabled (1 = enabled, 0 = disabled)
    entity_debug_mode: u32,       // US-0M04: Entity debug mode (0=off, 1=position as RGB, 2=count as brightness)
    terrain_visible: u32,         // US-0N01: Whether terrain is visible (1 = visible, 0 = hidden via F1 toggle)
    camera_mode: u32,             // US-019: Camera mode (0 = third-person, 1 = first-person)
}

@group(0) @binding(0)
var<uniform> uniforms: Uniforms;

// ============================================================================
// ENTITY STORAGE BUFFER
// ============================================================================

// SDF type constants
const SDF_SPHERE: u32 = 0u;
const SDF_BOX: u32 = 1u;
const SDF_CAPSULE: u32 = 2u;

// GpuEntity layout (96 bytes total, matches Rust GpuEntity):
// IMPORTANT: We use scalar fields (position_x, position_y, position_z) instead of vec3<f32>
// because in WGSL storage buffers, vec3<f32> has 16-byte alignment which would cause
// the struct to be 128 bytes instead of 96 bytes.
// The Rust struct uses [f32; 3] which has 4-byte alignment, so scalar fields match.
//
// Layout (total 96 bytes, 6 rows of 16 bytes each):
// Row 0 (offset 0-15):  position_x, position_y, position_z, sdf_type
// Row 1 (offset 16-31): scale_x, scale_y, scale_z, seed
// Row 2 (offset 32-47): rotation (vec4)
// Row 3 (offset 48-63): color_r, color_g, color_b, roughness
// Row 4 (offset 64-79): metallic, selected, lod_octaves, use_noise
// Row 5 (offset 80-95): noise_amplitude, noise_frequency, noise_octaves, _padding
//
// Byte offset summary (for debugging buffer mismatches):
//   offset  0: position_x (f32)
//   offset  4: position_y (f32)
//   offset  8: position_z (f32)
//   offset 12: sdf_type (u32)
//   offset 16: scale_x (f32)
//   offset 20: scale_y (f32)
//   offset 24: scale_z (f32)
//   offset 28: seed (f32)
//   offset 32: rotation.x (f32)
//   offset 36: rotation.y (f32)
//   offset 40: rotation.z (f32)
//   offset 44: rotation.w (f32)
//   offset 48: color_r (f32)
//   offset 52: color_g (f32)
//   offset 56: color_b (f32)
//   offset 60: roughness (f32)
//   offset 64: metallic (f32)
//   offset 68: selected (f32)
//   offset 72: lod_octaves (u32)
//   offset 76: use_noise (u32)
//   offset 80: noise_amplitude (f32)
//   offset 84: noise_frequency (f32)
//   offset 88: noise_octaves (u32)
//   offset 92: baked_sdf_id (u32) - Baked SDF slot ID (0 = not baked, use equation evaluation)
//   TOTAL: 96 bytes
struct GpuEntity {
    // Row 0: position (3 floats) + sdf_type = 16 bytes (offset 0-15)
    position_x: f32,      // offset 0
    position_y: f32,      // offset 4
    position_z: f32,      // offset 8
    sdf_type: u32,        // offset 12
    // Row 1: scale (3 floats) + seed = 16 bytes (offset 16-31)
    scale_x: f32,         // offset 16
    scale_y: f32,         // offset 20
    scale_z: f32,         // offset 24
    seed: f32,            // offset 28
    // Row 2: rotation quaternion (vec4 is OK, has 16-byte alignment) = 16 bytes (offset 32-47)
    rotation: vec4<f32>,  // offset 32 (vec4 has consistent 16-byte alignment)
    // Row 3: color (3 floats) + roughness = 16 bytes (offset 48-63)
    color_r: f32,         // offset 48
    color_g: f32,         // offset 52
    color_b: f32,         // offset 56
    roughness: f32,       // offset 60
    // Row 4: metallic + selected + lod_octaves + use_noise = 16 bytes (offset 64-79)
    metallic: f32,        // offset 64
    selected: f32,        // offset 68 (1.0 if selected, 0.0 otherwise)
    lod_octaves: u32,     // offset 72 (LOD level octave count 1-8 for noise functions)
    use_noise: u32,       // offset 76 (1 if noise displacement enabled, 0 otherwise)
    // Row 5: noise_amplitude + noise_frequency + noise_octaves + baked_sdf_id = 16 bytes (offset 80-95)
    noise_amplitude: f32, // offset 80 (amplitude of noise displacement)
    noise_frequency: f32, // offset 84 (frequency multiplier for noise)
    noise_octaves: u32,   // offset 88 (number of octaves for FBM noise 1-8)
    baked_sdf_id: u32,    // offset 92 (baked SDF slot ID, 0 = not baked, use equation evaluation)
}

// Helper functions to extract vec3 from GpuEntity scalar fields
fn get_entity_position(entity: GpuEntity) -> vec3<f32> {
    return vec3<f32>(entity.position_x, entity.position_y, entity.position_z);
}

fn get_entity_scale(entity: GpuEntity) -> vec3<f32> {
    return vec3<f32>(entity.scale_x, entity.scale_y, entity.scale_z);
}

fn get_entity_color(entity: GpuEntity) -> vec3<f32> {
    return vec3<f32>(entity.color_r, entity.color_g, entity.color_b);
}

// EntityBuffer layout (matches Rust EntityBufferHeader + array<GpuEntity>):
// - count: u32 (4 bytes)
// - _padding0-2: 3x u32 (12 bytes) - NOT vec3<u32> to avoid 16-byte alignment issues
// Total header: 16 bytes
// Note: We use separate u32 fields instead of vec3<u32> because vec3 has 16-byte
// alignment in WGSL, which would push the array start to offset 32 instead of 16.
struct EntityBuffer {
    count: u32,
    _padding0: u32,
    _padding1: u32,
    _padding2: u32,
    entities: array<GpuEntity>,
}

@group(0) @binding(1)
var<storage, read> entity_buffer: EntityBuffer;

// ============================================================================
// TERRAIN CONFIGURATION
// ============================================================================

// TerrainConfig layout (matches Rust GpuTerrainConfig):
// - amplitude: f32 (4 bytes)   offset 0
// - frequency: f32 (4 bytes)   offset 4
// - octaves: u32 (4 bytes)     offset 8
// - enabled: u32 (4 bytes)     offset 12
// - seed: f32 (4 bytes)        offset 16
// - _pad1_0-2: 3x u32 (12 bytes) offset 20
// - _padding_0-2: 3x u32 (12 bytes) offset 32
// - _pad2: u32 (4 bytes)       offset 44
// Total: 48 bytes
struct TerrainConfig {
    amplitude: f32,
    frequency: f32,
    octaves: u32,
    enabled: u32,
    seed: f32,
    _pad1_0: u32,
    _pad1_1: u32,
    _pad1_2: u32,
    _padding_0: u32,
    _padding_1: u32,
    _padding_2: u32,
    _pad2: u32,
}

@group(0) @binding(2)
var<uniform> terrain_config: TerrainConfig;

// ============================================================================
// BAKED SDF TEXTURE ARRAY
// ============================================================================
//
// Baked SDFs are stored as a 2D texture array where each SDF occupies 64 consecutive layers.
// - Texture dimensions: 64 × 64 (XY slices)
// - Array layers: 64 per SDF × 256 max SDFs = 16384 total layers
// - Format: R16Float (signed distance values)
// - Each SDF ID maps to layers [id * 64, id * 64 + 63]
//
// Trilinear interpolation is performed manually:
// 1. Hardware bilinear interpolation on XY (via sampler)
// 2. Manual linear interpolation on Z (between adjacent layers)

// Resolution of each baked SDF volume (64³ voxels)
const BAKED_SDF_RESOLUTION: f32 = 64.0;

// Baked SDF texture array binding (group 1 to avoid conflicts with main bind group)
@group(1) @binding(0)
var baked_sdf_texture: texture_2d_array<f32>;

@group(1) @binding(1)
var baked_sdf_sampler: sampler;

// ============================================================================
// TILE CULLING BUFFER (US-017)
// ============================================================================
//
// Tile-based culling data from compute shader (US-010).
// The screen is divided into 16×16 pixel tiles, and each tile stores
// up to 32 entity indices that potentially overlap that tile.
//
// This allows the raymarcher to only evaluate entities relevant to
// each pixel's tile, dramatically reducing SDF evaluations.
//
// Binding group 2 is used to separate from main render and baked SDF bindings.

const TILE_SIZE: u32 = 16u;
const MAX_ENTITIES_PER_TILE: u32 = 32u;

// TileData for read-only access (no atomics in fragment shader)
// Matches WGSL TileData struct layout from culling.wgsl
struct TileDataReadOnly {
    entity_count: u32,
    _padding: u32,
    entity_indices: array<u32, 32>,
}

// TileBufferReadOnly: Complete tile buffer for reading in fragment shader
struct TileBufferReadOnly {
    tiles_x: u32,
    tiles_y: u32,
    tile_size: u32,
    total_tiles: u32,
    tiles: array<TileDataReadOnly>,
}

@group(2) @binding(0)
var<storage, read> tile_buffer: TileBufferReadOnly;

// Global flag to enable/disable tile culling (set via uniform in future, currently always on)
// When tile_buffer.total_tiles == 0, fallback to full entity list
fn is_tile_culling_enabled() -> bool {
    return tile_buffer.total_tiles > 0u;
}

// Get tile index for a given pixel coordinate
fn get_tile_index_for_pixel(pixel_x: u32, pixel_y: u32) -> u32 {
    let tile_x = pixel_x / TILE_SIZE;
    let tile_y = pixel_y / TILE_SIZE;
    return tile_y * tile_buffer.tiles_x + tile_x;
}

// Get entity count for a tile (clamped to max)
fn get_tile_entity_count(tile_index: u32) -> u32 {
    if (tile_index >= tile_buffer.total_tiles) {
        return 0u;
    }
    return min(tile_buffer.tiles[tile_index].entity_count, MAX_ENTITIES_PER_TILE);
}

// Get entity index from a tile's entity list
fn get_tile_entity_index(tile_index: u32, slot: u32) -> u32 {
    return tile_buffer.tiles[tile_index].entity_indices[slot];
}

// ============================================================================
// RAY MARCHING CONSTANTS
// ============================================================================

// NOTE: 1 unit = 1 meter (SI units)
const MAX_DIST: f32 = 5000.0;  // 5km visibility for spherical world
const SURFACE_DIST: f32 = 0.001;
const NORMAL_EPSILON: f32 = 0.001;

// ============================================================================
// SPHERICAL WORLD CONSTANTS
// ============================================================================

// World size: 10km x 10km (map_size = 5000, so -5000 to +5000)
const WORLD_MAP_SIZE: f32 = 5000.0;
const WORLD_DIAMETER: f32 = 10000.0;  // 10km

// Planet radius for curvature calculation
// For a 10km "circumference" world: circumference = 20000m (wrap in both X and Z)
// radius = circumference / (2π) ≈ 3183m
const PLANET_RADIUS: f32 = 3183.0;

// Curvature drop formula: drop = distance² / (2 * radius)
// At 100m: drop ≈ 1.57m
// At 500m: drop ≈ 39m
// At 1km: drop ≈ 157m
fn curvature_drop(distance: f32) -> f32 {
    return (distance * distance) / (2.0 * PLANET_RADIUS);
}

// Wrap position for spherical world (like walking around a planet)
fn wrap_world_position(pos: vec3<f32>) -> vec3<f32> {
    var p = pos;
    // Wrap X
    if (p.x > WORLD_MAP_SIZE) {
        p.x = p.x - WORLD_DIAMETER;
    } else if (p.x < -WORLD_MAP_SIZE) {
        p.x = p.x + WORLD_DIAMETER;
    }
    // Wrap Z
    if (p.z > WORLD_MAP_SIZE) {
        p.z = p.z - WORLD_DIAMETER;
    } else if (p.z < -WORLD_MAP_SIZE) {
        p.z = p.z + WORLD_DIAMETER;
    }
    return p;
}

// ============================================================================
// LOD CONSTANTS
// ============================================================================

// LOD level octave counts for adaptive detail rendering
const LOD_FULL_OCTAVES: u32 = 8u;       // Near objects (< 10 units)
const LOD_MEDIUM_OCTAVES: u32 = 4u;     // Medium distance (10-50 units)
const LOD_LOW_OCTAVES: u32 = 2u;        // Far objects (50-200 units)
const LOD_SILHOUETTE_OCTAVES: u32 = 1u; // Very far (>= 200 units)

// Distance thresholds for LOD transitions
const LOD_SILHOUETTE_DISTANCE: f32 = 200.0;  // Distance at which silhouette mode activates
const LOD_SILHOUETTE_BLEND_RANGE: f32 = 50.0; // Blend range for smooth transition to silhouette

// LOD debug visualization colors (specified in task requirements)
// Green = Full detail (< 10 units, 8 octaves)
// Yellow = Medium detail (10-50 units, 4 octaves)
// Orange = Low detail (50-200 units, 2 octaves)
// Red = Silhouette mode (>= 200 units, 1 octave)
const LOD_DEBUG_COLOR_FULL: vec3<f32> = vec3<f32>(0.2, 0.9, 0.2);       // Green
const LOD_DEBUG_COLOR_MEDIUM: vec3<f32> = vec3<f32>(0.95, 0.9, 0.2);    // Yellow
const LOD_DEBUG_COLOR_LOW: vec3<f32> = vec3<f32>(1.0, 0.6, 0.1);        // Orange
const LOD_DEBUG_COLOR_SILHOUETTE: vec3<f32> = vec3<f32>(0.95, 0.2, 0.2); // Red

// Distance thresholds for LOD debug coloring (matching LodConfig defaults)
const LOD_NEAR_DISTANCE: f32 = 10.0;    // Full detail threshold
const LOD_MEDIUM_DISTANCE: f32 = 50.0;  // Medium detail threshold
const LOD_FAR_DISTANCE: f32 = 200.0;    // Low detail threshold (same as silhouette)

// Get LOD debug color based on distance from camera
fn get_lod_debug_color(distance: f32) -> vec3<f32> {
    if (distance < LOD_NEAR_DISTANCE) {
        return LOD_DEBUG_COLOR_FULL;
    } else if (distance < LOD_MEDIUM_DISTANCE) {
        return LOD_DEBUG_COLOR_MEDIUM;
    } else if (distance < LOD_FAR_DISTANCE) {
        return LOD_DEBUG_COLOR_LOW;
    } else {
        return LOD_DEBUG_COLOR_SILHOUETTE;
    }
}

// ============================================================================
// SDF PRIMITIVES (imported from sdf_primitives.wgsl at compile time)
// ============================================================================

fn sdf_sphere(p: vec3<f32>, radius: f32) -> f32 {
    return length(p) - radius;
}

fn sdf_box(p: vec3<f32>, half_extents: vec3<f32>) -> f32 {
    let q = abs(p) - half_extents;
    return length(max(q, vec3<f32>(0.0))) + min(max(q.x, max(q.y, q.z)), 0.0);
}

fn sdf_capsule(p: vec3<f32>, height: f32, radius: f32) -> f32 {
    let half_height = height * 0.5;
    let p_clamped = vec3<f32>(p.x, clamp(p.y, -half_height, half_height), p.z);
    return length(p - p_clamped) - radius;
}

// ============================================================================
// BAKED SDF SAMPLING
// ============================================================================
//
// sample_baked_sdf performs trilinear interpolation from the baked SDF texture array.
//
// The baked SDF uses a normalized coordinate system:
// - Local position (0, 0, 0) maps to texture center (0.5, 0.5, 0.5)
// - Local position range [-0.5, 0.5] maps to texture range [0.0, 1.0]
// - Positions outside this range return MAX_DIST (out of bounds)
//
// The 3D volume is stored as a 2D texture array:
// - Each SDF slot has 64 consecutive layers (Z slices)
// - Slot ID maps to base layer: slot_id * 64
//
// Trilinear interpolation:
// - XY: Hardware bilinear via sampler (linear filtering)
// - Z: Manual linear interpolation between adjacent layers

/// Sample a baked SDF from the 3D texture array.
///
/// Parameters:
/// - id: The baked SDF slot ID (0-255)
/// - local_pos: Position in entity local space, normalized to [-0.5, 0.5] range
///
/// Returns:
/// - Signed distance value, or MAX_DIST if out of bounds or id is 0 (unbaked)
fn sample_baked_sdf(id: u32, local_pos: vec3<f32>) -> f32 {
    // ID 0 means entity is not baked (use equation-based SDF)
    if (id == 0u) {
        return MAX_DIST;
    }

    // Validate ID range (max 256 slots)
    if (id >= 256u) {
        return MAX_DIST;
    }

    // Convert local position to normalized texture coordinates [0, 1]
    // Local space: [-0.5, 0.5] -> Texture space: [0.0, 1.0]
    let uv = local_pos + vec3<f32>(0.5);

    // Check bounds - return MAX_DIST if outside the baked volume
    if (any(uv < vec3<f32>(0.0)) || any(uv > vec3<f32>(1.0))) {
        return MAX_DIST;
    }

    // Calculate the base layer index for this SDF slot
    // Each SDF occupies 64 consecutive layers in the texture array
    let base_layer = id * 64u;

    // Convert Z coordinate to layer index with fractional part for interpolation
    // Z range [0, 1] maps to layers [base_layer, base_layer + 63]
    let z_float = uv.z * (BAKED_SDF_RESOLUTION - 1.0);
    let z_low = u32(floor(z_float));
    let z_high = min(z_low + 1u, 63u);  // Clamp to valid layer range
    let z_frac = fract(z_float);

    // Sample XY slice at the two Z layers using hardware bilinear filtering
    // The sampler uses ClampToEdge, so we don't need to worry about UV bounds
    let layer_low = base_layer + z_low;
    let layer_high = base_layer + z_high;

    // Sample from both layers - textureSample does XY bilinear interpolation
    let sample_low = textureSample(baked_sdf_texture, baked_sdf_sampler, uv.xy, i32(layer_low)).r;
    let sample_high = textureSample(baked_sdf_texture, baked_sdf_sampler, uv.xy, i32(layer_high)).r;

    // Manual linear interpolation along Z axis (trilinear completion)
    return mix(sample_low, sample_high, z_frac);
}

/// Transform world position to entity local space for baked SDF sampling.
///
/// This function handles the transformation from world coordinates to the
/// normalized local space used by baked SDFs.
///
/// Parameters:
/// - world_pos: Position in world space
/// - entity_pos: Entity's world position (center)
/// - entity_rotation: Entity's rotation quaternion
/// - entity_scale: Entity's uniform scale factor
///
/// Returns:
/// - Position in normalized local space [-0.5, 0.5] suitable for sample_baked_sdf
fn world_to_baked_local(
    world_pos: vec3<f32>,
    entity_pos: vec3<f32>,
    entity_rotation: vec4<f32>,
    entity_scale: f32
) -> vec3<f32> {
    // Translate to entity origin
    let relative_pos = world_pos - entity_pos;

    // Rotate to entity local space (inverse rotation)
    let inv_rotation = quat_inverse(entity_rotation);
    let rotated_pos = quat_rotate(inv_rotation, relative_pos);

    // Apply inverse scale and normalize to [-0.5, 0.5] range
    // Baked SDFs are normalized to unit cube centered at origin
    // Scale determines the world-space size of the baked volume
    return rotated_pos / entity_scale;
}

// ============================================================================
// BLENDING OPERATIONS
// ============================================================================

// Smooth minimum (polynomial smooth min)
// Creates smooth blending/union between two SDF values
// a, b: distance values to blend
// k: smoothness factor (larger = smoother blend, 0 = hard union)
fn smooth_min(a: f32, b: f32, k: f32) -> f32 {
    if (k <= 0.0) {
        return min(a, b);
    }
    let h = max(k - abs(a - b), 0.0) / k;
    return min(a, b) - h * h * k * 0.25;
}

// Alias for smooth_min
fn smin(a: f32, b: f32, k: f32) -> f32 {
    return smooth_min(a, b, k);
}

// LOD-aware smooth minimum
// Adapts smoothness based on distance for performance optimization
// a, b: distance values to blend
// k: base smoothness factor
// distance: distance from camera to the evaluation point
// Near objects (distance < 100) use specified k for full quality
// Far objects (distance > 100) use larger k for cheaper, less detailed blending
fn smin_lod(a: f32, b: f32, k: f32, distance: f32) -> f32 {
    // Scale k based on distance: k * clamp(distance / 100.0, 0.1, 2.0)
    // - At distance 10: k * 0.1 (tighter blend, more detail)
    // - At distance 100: k * 1.0 (base smoothness)
    // - At distance 200+: k * 2.0 (looser blend, cheaper)
    let lod_scale = clamp(distance / 100.0, 0.1, 2.0);
    let lod_k = k * lod_scale;
    return smooth_min(a, b, lod_k);
}

// ============================================================================
// QUATERNION MATH
// ============================================================================

fn quat_rotate(q: vec4<f32>, v: vec3<f32>) -> vec3<f32> {
    let qv = vec3<f32>(q.x, q.y, q.z);
    let uv = cross(qv, v);
    let uuv = cross(qv, uv);
    return v + ((uv * q.w) + uuv) * 2.0;
}

fn quat_inverse(q: vec4<f32>) -> vec4<f32> {
    return vec4<f32>(-q.x, -q.y, -q.z, q.w);
}

// ============================================================================
// NOISE FUNCTIONS FOR DISPLACEMENT
// ============================================================================

// 3D to 3D hash function for gradient noise
fn hash33(p: vec3<f32>) -> vec3<f32> {
    var p3 = fract(p * vec3<f32>(0.1031, 0.1030, 0.0973));
    p3 = p3 + dot(p3, p3.yxz + 33.33);
    return fract((p3.xxy + p3.yxx) * p3.zyx);
}

// 3D Gradient noise with smoothstep interpolation
fn noise_3d(p: vec3<f32>) -> f32 {
    let i = floor(p);
    let f = fract(p);

    // Smoothstep interpolation (3t^2 - 2t^3)
    let u = f * f * (3.0 - 2.0 * f);

    // Sample gradients at 8 corners and compute dot products
    return mix(
        mix(
            mix(dot(hash33(i + vec3<f32>(0.0, 0.0, 0.0)) * 2.0 - 1.0, f - vec3<f32>(0.0, 0.0, 0.0)),
                dot(hash33(i + vec3<f32>(1.0, 0.0, 0.0)) * 2.0 - 1.0, f - vec3<f32>(1.0, 0.0, 0.0)), u.x),
            mix(dot(hash33(i + vec3<f32>(0.0, 1.0, 0.0)) * 2.0 - 1.0, f - vec3<f32>(0.0, 1.0, 0.0)),
                dot(hash33(i + vec3<f32>(1.0, 1.0, 0.0)) * 2.0 - 1.0, f - vec3<f32>(1.0, 1.0, 0.0)), u.x),
            u.y
        ),
        mix(
            mix(dot(hash33(i + vec3<f32>(0.0, 0.0, 1.0)) * 2.0 - 1.0, f - vec3<f32>(0.0, 0.0, 1.0)),
                dot(hash33(i + vec3<f32>(1.0, 0.0, 1.0)) * 2.0 - 1.0, f - vec3<f32>(1.0, 0.0, 1.0)), u.x),
            mix(dot(hash33(i + vec3<f32>(0.0, 1.0, 1.0)) * 2.0 - 1.0, f - vec3<f32>(0.0, 1.0, 1.0)),
                dot(hash33(i + vec3<f32>(1.0, 1.0, 1.0)) * 2.0 - 1.0, f - vec3<f32>(1.0, 1.0, 1.0)), u.x),
            u.y
        ),
        u.z
    );
}

// Standard FBM with configurable octaves for noise displacement
fn fbm_displacement(p: vec3<f32>, octaves: i32) -> f32 {
    var value = 0.0;
    var amplitude = 0.5;
    var frequency = 1.0;
    var pos = p;

    for (var i = 0; i < octaves; i = i + 1) {
        value = value + amplitude * noise_3d(pos * frequency);
        amplitude = amplitude * 0.5;
        frequency = frequency * 2.0;
    }

    return value;
}

// LOD-aware FBM with smooth octave blending
// Reduces octaves based on distance to prevent popping artifacts
// distance: distance from camera to the sample point
// base_octaves: maximum number of octaves at full detail (typically 4-8)
// Returns FBM value with dynamically adjusted octave count
fn fbm_lod(p: vec3<f32>, distance: f32, base_octaves: i32) -> f32 {
    // Calculate effective octave count based on distance
    // Formula: octaves = max(1, base_octaves - floor(distance / 50))
    let octave_reduction = i32(floor(distance / 50.0));
    let effective_octaves_i = max(1, base_octaves - octave_reduction);

    // Calculate fractional part for smooth blending between LOD levels
    // This prevents popping when transitioning between octave counts
    let distance_in_band = distance - floor(distance / 50.0) * 50.0;
    let blend_factor = distance_in_band / 50.0;  // 0.0 to 1.0 within each 50-unit band

    // Compute FBM at current octave level
    var value = 0.0;
    var amplitude = 0.5;
    var frequency = 1.0;

    for (var i = 0; i < effective_octaves_i; i = i + 1) {
        value = value + amplitude * noise_3d(p * frequency);
        amplitude = amplitude * 0.5;
        frequency = frequency * 2.0;
    }

    // Add partial contribution from the next octave for smooth blending
    // This creates a gradual fade-out of detail rather than abrupt pops
    if (effective_octaves_i < base_octaves && blend_factor > 0.0) {
        // Inverse blend: stronger at start of band, fades toward end
        let octave_blend = 1.0 - blend_factor;
        value = value + amplitude * noise_3d(p * frequency) * octave_blend;
    }

    return value;
}

// LOD-aware FBM with custom parameters
// Provides full control over lacunarity and gain for specialized noise patterns
fn fbm_lod_params(p: vec3<f32>, distance: f32, base_octaves: i32, lacunarity: f32, gain: f32) -> f32 {
    let octave_reduction = i32(floor(distance / 50.0));
    let effective_octaves_i = max(1, base_octaves - octave_reduction);

    let distance_in_band = distance - floor(distance / 50.0) * 50.0;
    let blend_factor = distance_in_band / 50.0;

    var value = 0.0;
    var amplitude = 0.5;
    var frequency = 1.0;

    for (var i = 0; i < effective_octaves_i; i = i + 1) {
        value = value + amplitude * noise_3d(p * frequency);
        amplitude = amplitude * gain;
        frequency = frequency * lacunarity;
    }

    // Smooth blend for next octave
    if (effective_octaves_i < base_octaves && blend_factor > 0.0) {
        let octave_blend = 1.0 - blend_factor;
        value = value + amplitude * noise_3d(p * frequency) * octave_blend;
    }

    return value;
}

// ============================================================================
// TERRAIN SDF
// ============================================================================

// 2D to 2D hash function for terrain noise
fn hash22(p: vec2<f32>) -> vec2<f32> {
    var p3 = fract(vec3<f32>(p.xyx) * vec3<f32>(0.1031, 0.1030, 0.0973));
    p3 = p3 + dot(p3, p3.yzx + 33.33);
    return fract((p3.xx + p3.yz) * p3.zy);
}

// 2D gradient noise for terrain heightmap
fn noise_2d(p: vec2<f32>) -> f32 {
    let i = floor(p);
    let f = fract(p);

    // Smoothstep interpolation
    let u = f * f * (3.0 - 2.0 * f);

    // Sample 4 corners and interpolate
    let a = hash22(i + vec2<f32>(0.0, 0.0)).x;
    let b = hash22(i + vec2<f32>(1.0, 0.0)).x;
    let c = hash22(i + vec2<f32>(0.0, 1.0)).x;
    let d = hash22(i + vec2<f32>(1.0, 1.0)).x;

    return mix(mix(a, b, u.x), mix(c, d, u.x), u.y) * 2.0 - 1.0;
}

// FBM for terrain heightmap using 2D noise on the xz plane
// Returns height value based on FBM of the xz coordinates
fn fbm_terrain(p: vec2<f32>, octaves: i32, seed: f32) -> f32 {
    var value = 0.0;
    var amplitude = 0.5;
    var frequency = 1.0;
    var pos = p + vec2<f32>(seed * 17.3, seed * 31.7);

    for (var i = 0; i < octaves; i = i + 1) {
        value = value + amplitude * noise_2d(pos * frequency);
        amplitude = amplitude * 0.5;
        frequency = frequency * 2.0;
    }

    return value;
}

// Terrain SDF: ground plane with height variation from FBM noise and planet curvature
// Formula: terrain_sdf(p) = p.y - fbm(p.xz * frequency, octaves) * amplitude - curvature_drop(distance)
//
// The curvature drop makes distant terrain "sink" below the horizon, creating the illusion
// of standing on a spherical planet. This is especially visible at distances > 500m.
fn terrain_sdf(p: vec3<f32>) -> f32 {
    // Base terrain height from noise
    let height = fbm_terrain(
        p.xz * terrain_config.frequency,
        i32(terrain_config.octaves),
        terrain_config.seed
    ) * terrain_config.amplitude;

    // Calculate distance from camera for curvature drop
    // This creates the "over the horizon" effect on a spherical world
    let dist_from_camera = length(p.xz - uniforms.camera_pos.xz);
    let drop = curvature_drop(dist_from_camera);

    // Terrain surface = base height minus curvature drop
    // As distance increases, the terrain "drops" below the horizon
    return p.y - height + drop;
}

// Terrain color based on height and slope
const TERRAIN_COLOR_LOW: vec3<f32> = vec3<f32>(0.2, 0.35, 0.15);   // Grass/lowlands
const TERRAIN_COLOR_HIGH: vec3<f32> = vec3<f32>(0.45, 0.4, 0.35);  // Rocky/highlands

// ============================================================================
// SDF WITH NOISE DISPLACEMENT
// ============================================================================

/// Applies noise displacement to an SDF value.
///
/// Formula: sdf(p) + fbm(p * frequency, octaves) * amplitude
///
/// Parameters:
/// - base_sdf: The base SDF value at point p
/// - world_p: World-space position for noise sampling (ensures consistent noise across transforms)
/// - frequency: Noise frequency multiplier (higher = more detail)
/// - octaves: Number of FBM octaves (1-8, more = more detail but slower)
/// - amplitude: Noise amplitude (strength of displacement)
fn sdf_with_noise(base_sdf: f32, world_p: vec3<f32>, frequency: f32, octaves: i32, amplitude: f32) -> f32 {
    let noise_value = fbm_displacement(world_p * frequency, octaves);
    return base_sdf + noise_value * amplitude;
}

/// Applies LOD-aware noise displacement to an SDF value.
/// Reduces octaves based on distance from camera for performance optimization.
///
/// Parameters:
/// - base_sdf: The base SDF value at point p
/// - world_p: World-space position for noise sampling
/// - frequency: Noise frequency multiplier
/// - base_octaves: Maximum number of FBM octaves at full detail
/// - amplitude: Noise amplitude (strength of displacement)
/// - camera_distance: Distance from camera to the sample point
fn sdf_with_noise_lod(base_sdf: f32, world_p: vec3<f32>, frequency: f32, base_octaves: i32, amplitude: f32, camera_distance: f32) -> f32 {
    // In silhouette mode, skip noise entirely for maximum performance
    if (camera_distance >= LOD_SILHOUETTE_DISTANCE) {
        return base_sdf;
    }

    // Use LOD-aware FBM with smooth octave blending
    let noise_value = fbm_lod(world_p * frequency, camera_distance, base_octaves);

    // Fade out noise amplitude as we approach silhouette distance
    // This ensures smooth transition to no-noise silhouette mode
    let silhouette_blend_start = LOD_SILHOUETTE_DISTANCE - LOD_SILHOUETTE_BLEND_RANGE;
    var amplitude_scale = 1.0;
    if (camera_distance > silhouette_blend_start) {
        let blend_factor = (camera_distance - silhouette_blend_start) / LOD_SILHOUETTE_BLEND_RANGE;
        amplitude_scale = 1.0 - smoothstep(0.0, 1.0, blend_factor);
    }

    return base_sdf + noise_value * amplitude * amplitude_scale;
}

// ============================================================================
// PREVIEW SDF EVALUATION
// ============================================================================

// Preview ghost appearance constants
const PREVIEW_SCALE: f32 = 1.0;            // Default scale for preview objects
const PREVIEW_COLOR: vec3<f32> = vec3<f32>(0.4, 0.8, 1.0);  // Cyan ghost color
const PREVIEW_ALPHA: f32 = 0.5;            // Semi-transparency

/// Evaluate the preview SDF at a given point.
/// Returns the signed distance to the preview object, or MAX_DIST if preview is disabled.
fn evaluate_preview_sdf(p: vec3<f32>) -> f32 {
    if (uniforms.preview_enabled == 0u) {
        return MAX_DIST;
    }

    // Transform point to preview local space (centered at preview_position)
    let local_p = p - uniforms.preview_position;

    var d: f32 = MAX_DIST;

    switch uniforms.preview_sdf_type {
        case SDF_SPHERE: {
            // Sphere with radius 1.0 (default scale)
            d = sdf_sphere(local_p, PREVIEW_SCALE);
        }
        case SDF_BOX: {
            // Box with half extents 1.0
            d = sdf_box(local_p, vec3<f32>(PREVIEW_SCALE));
        }
        case SDF_CAPSULE: {
            // Capsule with height 2.0 and radius 1.0
            d = sdf_capsule(local_p, 2.0 * PREVIEW_SCALE, PREVIEW_SCALE);
        }
        default: {
            d = MAX_DIST;
        }
    }

    return d;
}

// ============================================================================
// SCENE SDF EVALUATION
// ============================================================================

struct HitResult {
    dist: f32,
    entity_index: i32,
    lod_octaves: u32,  // LOD octave count from the closest entity
    is_terrain: u32,   // 1 if terrain hit, 0 otherwise
    is_preview: u32,   // 1 if preview hit, 0 otherwise
    is_marker: u32,    // 1 if distance reference marker, 0 otherwise
    is_hands: u32,     // US-019: 1 if first-person hand was hit, 0 otherwise
    marker_distance: f32,  // Distance of the marker from origin (10, 25, 50, 100, 1000)
}

// ============================================================================
// DISTANCE REFERENCE MARKERS
// ============================================================================
// Trees/poles at 10m, 25m, 50m, 100m, 1000m in all 4 cardinal directions (N, S, E, W)
// Each marker is a tree: trunk (capsule) + foliage (sphere on top)
// Tree heights scale with distance: 10m marker = 5m tree, 1km marker = 50m tree

// Tree SDF: trunk (capsule) + foliage (sphere) smoothly blended
fn sdf_tree(p: vec3<f32>, height: f32) -> f32 {
    // Trunk: capsule from ground to 70% of height
    let trunk_height = height * 0.7;
    let trunk_radius = height * 0.05;
    let trunk_center = vec3<f32>(0.0, trunk_height * 0.5, 0.0);
    let trunk_p = p - trunk_center;
    let trunk = sdf_capsule(trunk_p, trunk_height, trunk_radius);

    // Foliage: sphere at top, radius = 30% of height
    let foliage_center = vec3<f32>(0.0, trunk_height + height * 0.15, 0.0);
    let foliage_radius = height * 0.25;
    let foliage = sdf_sphere(p - foliage_center, foliage_radius);

    // Smooth blend trunk and foliage
    return smooth_min(trunk, foliage, height * 0.1);
}

// Reference marker distances in meters
const MARKER_DISTANCES: array<f32, 5> = array<f32, 5>(10.0, 25.0, 50.0, 100.0, 1000.0);
// Tree heights for each distance marker (proportional to distance)
const MARKER_HEIGHTS: array<f32, 5> = array<f32, 5>(5.0, 8.0, 12.0, 20.0, 50.0);

// Evaluate all distance reference markers with planet curvature
// Returns (distance to nearest marker, marker's distance from origin)
// Trees are placed relative to the camera, and their Y position is adjusted
// for planet curvature (they "sink" below the horizon at distance)
fn evaluate_markers(p: vec3<f32>) -> vec2<f32> {
    var min_d: f32 = MAX_DIST;
    var marker_dist: f32 = 0.0;

    // Markers are placed relative to camera XZ position
    let cam_xz = uniforms.camera_pos.xz;

    // For each marker distance
    for (var i: i32 = 0; i < 5; i = i + 1) {
        let dist = MARKER_DISTANCES[i];
        let height = MARKER_HEIGHTS[i];

        // Curvature drop at this distance - trees sink below horizon
        let drop = curvature_drop(dist);

        // North (+Z) - relative to camera
        let north_pos = vec3<f32>(cam_xz.x, -drop, cam_xz.y + dist);
        let north_p = p - north_pos;
        let d_north = sdf_tree(north_p, height);
        if (d_north < min_d) {
            min_d = d_north;
            marker_dist = dist;
        }

        // South (-Z)
        let south_pos = vec3<f32>(cam_xz.x, -drop, cam_xz.y - dist);
        let south_p = p - south_pos;
        let d_south = sdf_tree(south_p, height);
        if (d_south < min_d) {
            min_d = d_south;
            marker_dist = dist;
        }

        // East (+X)
        let east_pos = vec3<f32>(cam_xz.x + dist, -drop, cam_xz.y);
        let east_p = p - east_pos;
        let d_east = sdf_tree(east_p, height);
        if (d_east < min_d) {
            min_d = d_east;
            marker_dist = dist;
        }

        // West (-X)
        let west_pos = vec3<f32>(cam_xz.x - dist, -drop, cam_xz.y);
        let west_p = p - west_pos;
        let d_west = sdf_tree(west_p, height);
        if (d_west < min_d) {
            min_d = d_west;
            marker_dist = dist;
        }
    }

    return vec2<f32>(min_d, marker_dist);
}

fn evaluate_entity_sdf(p: vec3<f32>, entity: GpuEntity) -> f32 {
    // Reconstruct vec3 from scalar fields (to match 96-byte struct layout)
    let entity_position = vec3<f32>(entity.position_x, entity.position_y, entity.position_z);
    let entity_scale = vec3<f32>(entity.scale_x, entity.scale_y, entity.scale_z);

    // Transform point to entity local space
    let local_p = quat_rotate(quat_inverse(entity.rotation), p - entity_position);
    let scaled_p = local_p / entity_scale;

    // Use minimum scale component for consistent distance scaling
    let min_scale = min(entity_scale.x, min(entity_scale.y, entity_scale.z));

    var d: f32 = MAX_DIST;

    // Check if this entity uses a baked SDF (baked_sdf_id != 0)
    // Baked SDFs provide O(1) lookup via texture sampling vs O(n) equation evaluation
    // Performance target: 5x faster than equation evaluation per entity
    if (entity.baked_sdf_id != 0u) {
        // BAKED SDF PATH: Use texture sampling with trilinear interpolation
        //
        // Transform world position to normalized local space for baked SDF sampling.
        // Baked SDFs use a normalized [-0.5, 0.5] coordinate system centered at entity origin.
        // The baking process captures the SDF in this normalized space.
        //
        // For uniform scale entities, we use the average scale to determine the sampling volume.
        // For non-uniform scale, the min_scale determines the bounding volume size.
        let baked_local_pos = world_to_baked_local(
            p,
            entity_position,
            entity.rotation,
            min_scale  // Use min_scale as the baked volume size
        );

        // Sample the baked SDF using trilinear interpolation
        // Returns MAX_DIST if position is outside the baked volume bounds
        let baked_d = sample_baked_sdf(entity.baked_sdf_id, baked_local_pos);

        // If within baked volume bounds, use baked distance
        // The baked SDF stores normalized distances, so we need to scale by entity size
        if (baked_d < MAX_DIST) {
            d = baked_d * min_scale;
        } else {
            // Outside baked volume - fall back to equation for this sample
            // This handles cases where rays extend beyond the baked region
            d = evaluate_entity_sdf_equation(scaled_p, entity.sdf_type) * min_scale;
        }
    } else {
        // EQUATION FALLBACK PATH: Use traditional SDF equation evaluation
        // Used when entity hasn't been baked (baked_sdf_id == 0)
        d = evaluate_entity_sdf_equation(scaled_p, entity.sdf_type) * min_scale;
    }

    // Apply noise displacement if enabled for this entity
    // Note: Noise is applied AFTER baked/equation evaluation for consistent results
    if (entity.use_noise == 1u) {
        // Use world-space position for consistent noise across transforms
        d = sdf_with_noise(
            d,
            p,
            entity.noise_frequency,
            i32(entity.noise_octaves),
            entity.noise_amplitude
        );
    }

    return d;
}

/// Evaluate SDF using equation-based primitives.
/// This is the fallback when no baked SDF is available (baked_sdf_id == 0)
/// or when sampling outside the baked volume bounds.
fn evaluate_entity_sdf_equation(scaled_p: vec3<f32>, sdf_type: u32) -> f32 {
    switch sdf_type {
        case SDF_SPHERE: {
            // Sphere uses scale.x as radius
            return sdf_sphere(scaled_p, 1.0);
        }
        case SDF_BOX: {
            // Box uses scale as half extents
            return sdf_box(scaled_p, vec3<f32>(1.0));
        }
        case SDF_CAPSULE: {
            // Capsule uses scale.y as height, scale.x as radius
            return sdf_capsule(scaled_p, 2.0, 1.0);
        }
        default: {
            return MAX_DIST;
        }
    }
}

// ============================================================================
// FIRST-PERSON HANDS SDF (US-019)
// ============================================================================
//
// First-person hands are rendered as capsules positioned relative to the camera.
// They are only visible in first-person mode (camera_mode == 1).
//
// Hand positions in camera space (relative to camera looking direction):
// - Left hand:  (-0.3, -0.3, 0.5) - 30cm left, 30cm down, 50cm forward
// - Right hand: ( 0.3, -0.3, 0.5) - 30cm right, 30cm down, 50cm forward
//
// The hands have a subtle idle bob animation based on time.

// First-person hand constants
const FP_HAND_RADIUS: f32 = 0.05;        // Hand capsule radius (5cm - realistic palm width)
const FP_HAND_LENGTH: f32 = 0.12;        // Hand capsule length (12cm - hand length)
const FP_HAND_BOB_AMPLITUDE: f32 = 0.01; // Subtle bob amplitude (1cm)
const FP_HAND_BOB_SPEED: f32 = 2.0;      // Bob animation speed
const FP_HAND_COLOR: vec3<f32> = vec3<f32>(0.9, 0.75, 0.6); // Skin tone (matches player body)

// Left hand offset in camera space (X=-0.3, Y=-0.3, Z=0.5)
const FP_LEFT_HAND_OFFSET: vec3<f32> = vec3<f32>(-0.3, -0.3, 0.5);
// Right hand offset in camera space (X=0.3, Y=-0.3, Z=0.5)
const FP_RIGHT_HAND_OFFSET: vec3<f32> = vec3<f32>(0.3, -0.3, 0.5);

/// Extract camera orientation vectors from the inverse view-projection matrix.
/// Returns (right, up, forward) vectors in world space.
fn get_camera_orientation() -> mat3x3<f32> {
    // The inverse view matrix (upper-left 3x3 of inv_view_proj) contains:
    // Column 0: camera right vector
    // Column 1: camera up vector
    // Column 2: camera forward vector (negative look direction)
    //
    // Note: We extract from inv_view_proj which includes perspective, so
    // we need to normalize the columns for accurate direction vectors.
    let right = normalize(vec3<f32>(
        uniforms.inv_view_proj[0][0],
        uniforms.inv_view_proj[0][1],
        uniforms.inv_view_proj[0][2]
    ));
    let up = normalize(vec3<f32>(
        uniforms.inv_view_proj[1][0],
        uniforms.inv_view_proj[1][1],
        uniforms.inv_view_proj[1][2]
    ));
    // Forward is the negative of the view direction in OpenGL convention
    let forward = normalize(vec3<f32>(
        -uniforms.inv_view_proj[2][0],
        -uniforms.inv_view_proj[2][1],
        -uniforms.inv_view_proj[2][2]
    ));
    return mat3x3<f32>(right, up, forward);
}

/// Transform a position from camera space to world space.
/// camera_local: position in camera space (X=right, Y=up, Z=forward)
/// Returns: position in world space
fn camera_to_world(camera_local: vec3<f32>) -> vec3<f32> {
    let orientation = get_camera_orientation();
    // Transform local position by camera orientation and add camera world position
    return uniforms.camera_pos
         + orientation[0] * camera_local.x  // right
         + orientation[1] * camera_local.y  // up
         + orientation[2] * camera_local.z; // forward
}

/// Calculate idle bob offset for hands.
/// Uses a sine wave with slight phase difference between hands.
fn hand_bob_offset(time: f32, is_left: bool) -> f32 {
    let phase = select(0.0, 0.5, is_left);
    return sin((time + phase) * FP_HAND_BOB_SPEED) * FP_HAND_BOB_AMPLITUDE;
}

/// Signed distance to a hand capsule.
/// p: world-space point to evaluate
/// hand_center: world-space center of the hand
fn sdf_hand_capsule(p: vec3<f32>, hand_center: vec3<f32>) -> f32 {
    // Simple sphere for the hand (capsule would need orientation which adds complexity)
    // Using a sphere here for simplicity, can be upgraded to capsule later
    return length(p - hand_center) - FP_HAND_RADIUS;
}

/// Evaluate first-person hands SDF.
/// Returns distance to nearest hand, or MAX_DIST if hands are not visible.
/// Only evaluates if camera_mode == 1 (first-person).
fn evaluate_first_person_hands(p: vec3<f32>) -> f32 {
    // Only render hands in first-person mode
    if (uniforms.camera_mode != 1u) {
        return MAX_DIST;
    }

    // Calculate bob offset for subtle idle animation
    let left_bob = hand_bob_offset(uniforms.time, true);
    let right_bob = hand_bob_offset(uniforms.time, false);

    // Calculate hand positions in camera space with bob animation
    let left_cam = FP_LEFT_HAND_OFFSET + vec3<f32>(0.0, left_bob, 0.0);
    let right_cam = FP_RIGHT_HAND_OFFSET + vec3<f32>(0.0, right_bob, 0.0);

    // Transform to world space
    let left_world = camera_to_world(left_cam);
    let right_world = camera_to_world(right_cam);

    // Evaluate SDF for both hands
    let d_left = sdf_hand_capsule(p, left_world);
    let d_right = sdf_hand_capsule(p, right_world);

    // Return minimum distance (closest hand)
    return min(d_left, d_right);
}

fn scene_sdf(p: vec3<f32>) -> HitResult {
    var result: HitResult;
    result.dist = MAX_DIST;
    result.entity_index = -1;
    result.lod_octaves = LOD_FULL_OCTAVES;
    result.is_terrain = 0u;
    result.is_preview = 0u;
    result.is_marker = 0u;
    result.is_hands = 0u;
    result.marker_distance = 0.0;

    // US-019: Evaluate first-person hands (highest priority - closest to camera)
    // Hands are only visible in first-person mode (camera_mode == 1)
    let hands_d = evaluate_first_person_hands(p);
    if (hands_d < result.dist) {
        result.dist = hands_d;
        result.entity_index = -4;  // Special index for first-person hands
        result.is_hands = 1u;
    }

    // Evaluate distance reference markers (trees at 10m, 25m, 50m, 100m, 1000m)
    let marker_result = evaluate_markers(p);
    if (marker_result.x < result.dist) {
        result.dist = marker_result.x;
        result.entity_index = -3;  // Special index for markers
        result.is_marker = 1u;
        result.is_hands = 0u;
        result.marker_distance = marker_result.y;
    }

    // US-0P04: Two-sided terrain SDF evaluation
    // Terrain is ALWAYS evaluated when enabled and visible, regardless of camera position.
    // This ensures entities are visible from any camera angle (above, below, or at terrain level).
    //
    // Two-sided terrain means:
    // - When camera is above terrain: rays hit terrain surface from above (normal case)
    // - When camera is below terrain: rays pass through terrain to reach entities
    //   (terrain rendered as semi-transparent or skipped based on ray direction)
    //
    // The key insight: we use the terrain SDF distance but DON'T let it block entity rays
    // when the camera is below terrain. This is achieved by only considering terrain hits
    // when the ray is traveling toward the terrain surface (not away from it).
    if (terrain_config.enabled == 1u && uniforms.terrain_visible == 1u) {
        let terrain_d = terrain_sdf(p);

        // Calculate terrain height at camera position for underground detection
        let camera_terrain_height = fbm_terrain(
            uniforms.camera_pos.xz * terrain_config.frequency,
            i32(terrain_config.octaves),
            terrain_config.seed
        ) * terrain_config.amplitude;

        // Determine if camera is above or below terrain at its current XZ position
        let camera_above_terrain = uniforms.camera_pos.y > camera_terrain_height;

        // Two-sided terrain handling:
        // - If camera is above terrain: use terrain_d normally (blocks rays from above)
        // - If camera is below terrain: only block rays if terrain_d is negative
        //   (meaning the sample point is inside/below terrain surface)
        //   This allows rays to pass through terrain to reach entities above
        var should_include_terrain = false;

        if (camera_above_terrain) {
            // Normal case: include terrain if it's closer than current result
            should_include_terrain = terrain_d < result.dist;
        } else {
            // Underground camera: only include terrain if we're looking at it from below
            // Use absolute distance for two-sided effect, but with reduced priority
            // so entities are still visible through the terrain
            let abs_terrain_d = abs(terrain_d);
            // Only include terrain if it's significantly closer and we're inside it
            should_include_terrain = abs_terrain_d < result.dist * 0.5 && terrain_d < 0.0;
        }

        if (should_include_terrain) {
            result.dist = select(terrain_d, abs(terrain_d), !camera_above_terrain);
            result.entity_index = -1;  // No entity, it's terrain
            result.is_terrain = 1u;
            result.is_preview = 0u;
            result.is_marker = 0u;
            result.is_hands = 0u;
        }
    }

    // Evaluate entities
    let count = entity_buffer.count;
    for (var i: u32 = 0u; i < count; i = i + 1u) {
        let entity = entity_buffer.entities[i];
        let d = evaluate_entity_sdf(p, entity);

        if (d < result.dist) {
            result.dist = d;
            result.entity_index = i32(i);
            result.lod_octaves = entity.lod_octaves;
            result.is_terrain = 0u;
            result.is_preview = 0u;
            result.is_marker = 0u;
            result.is_hands = 0u;
        }
    }

    // Evaluate preview object (always evaluated last so we can render it semi-transparently)
    let preview_d = evaluate_preview_sdf(p);
    if (preview_d < result.dist) {
        result.dist = preview_d;
        result.entity_index = -2;  // Special index for preview
        result.lod_octaves = LOD_FULL_OCTAVES;
        result.is_terrain = 0u;
        result.is_preview = 1u;
        result.is_marker = 0u;
        result.is_hands = 0u;
    }

    return result;
}

// ============================================================================
// RAY MARCHING
// ============================================================================

struct RayMarchResult {
    hit: bool,
    position: vec3<f32>,
    distance: f32,
    steps: u32,
    entity_index: i32,
    lod_octaves: u32,  // LOD octave count of the hit entity
    is_terrain: bool,  // True if terrain was hit
    is_preview: bool,  // True if preview object was hit
    is_marker: bool,   // True if distance reference marker was hit
    is_hands: bool,    // US-019: True if first-person hand was hit
    marker_distance: f32,  // Distance of the hit marker from origin (10, 25, 50, 100, 1000)
}

fn ray_march(ray_origin: vec3<f32>, ray_dir: vec3<f32>, max_steps: u32) -> RayMarchResult {
    var result: RayMarchResult;
    result.hit = false;
    result.position = ray_origin;
    result.distance = 0.0;
    result.steps = 0u;
    result.entity_index = -1;
    result.lod_octaves = LOD_FULL_OCTAVES;
    result.is_terrain = false;
    result.is_preview = false;
    result.is_marker = false;
    result.is_hands = false;
    result.marker_distance = 0.0;

    var t: f32 = 0.0;

    for (var i: u32 = 0u; i < max_steps; i = i + 1u) {
        let p = ray_origin + ray_dir * t;
        let hit = scene_sdf(p);

        result.steps = i + 1u;

        if (hit.dist < SURFACE_DIST) {
            result.hit = true;
            result.position = p;
            result.distance = t;
            result.entity_index = hit.entity_index;
            result.lod_octaves = hit.lod_octaves;
            result.is_terrain = hit.is_terrain == 1u;
            result.is_preview = hit.is_preview == 1u;
            result.is_marker = hit.is_marker == 1u;
            result.is_hands = hit.is_hands == 1u;
            result.marker_distance = hit.marker_distance;
            return result;
        }

        if (t > MAX_DIST) {
            break;
        }

        t = t + hit.dist;
    }

    result.distance = t;
    return result;
}

// ============================================================================
// NORMAL CALCULATION
// ============================================================================

fn calculate_normal(p: vec3<f32>) -> vec3<f32> {
    let e = vec2<f32>(NORMAL_EPSILON, 0.0);

    let n = vec3<f32>(
        scene_sdf(p + e.xyy).dist - scene_sdf(p - e.xyy).dist,
        scene_sdf(p + e.yxy).dist - scene_sdf(p - e.yxy).dist,
        scene_sdf(p + e.yyx).dist - scene_sdf(p - e.yyx).dist
    );

    return normalize(n);
}

// ============================================================================
// LIGHTING (basic directional light)
// ============================================================================

fn calculate_lighting(p: vec3<f32>, normal: vec3<f32>, color: vec3<f32>) -> vec3<f32> {
    // === AMBIENT LIGHTING ===
    // Higher ambient (0.25) ensures no pure black sides regardless of angle
    let ambient = 0.25;

    // === SUN LIGHT (Primary directional light) ===
    // Main light from upper-right-front, warm white color
    let sun_dir = normalize(vec3<f32>(0.5, 1.0, 0.3));
    let sun_color = vec3<f32>(1.0, 0.98, 0.95);
    let sun_diff = max(dot(normal, sun_dir), 0.0);

    // === CAMERA-RELATIVE FILL LIGHT ===
    // Fill light positioned relative to camera to ensure visibility from any angle
    // Uses a position offset from camera toward the surface for softer fill
    let view_dir = normalize(uniforms.camera_pos - p);
    // Fill light comes from camera direction with slight upward bias
    // This ensures underground/occluded surfaces get illumination when viewed
    let fill_dir = normalize(view_dir + vec3<f32>(0.0, 0.3, 0.0));
    let fill_color = vec3<f32>(0.6, 0.65, 0.8); // Cool blue-ish fill for contrast
    let fill_diff = max(dot(normal, fill_dir), 0.0);
    let fill_intensity = 0.35; // Moderate fill to avoid washing out

    // === HEMISPHERE/GROUND BOUNCE LIGHT ===
    // Additional fill from below to illuminate underground entities
    // Simulates light bouncing off the ground plane
    let ground_bounce_dir = vec3<f32>(0.0, -1.0, 0.0);
    let ground_bounce = max(dot(normal, -ground_bounce_dir), 0.0) * 0.15;
    let ground_bounce_color = vec3<f32>(0.4, 0.35, 0.3); // Warm earth tones

    // === RIM LIGHT ===
    // Subtle rim lighting for depth perception and edge definition
    let rim = pow(1.0 - max(dot(view_dir, normal), 0.0), 3.0) * 0.2;

    // === COMBINE ALL LIGHTING ===
    // Ambient base
    var final_color = color * ambient;

    // Add sun contribution (primary)
    final_color = final_color + color * sun_diff * 0.6 * sun_color;

    // Add camera-relative fill contribution (secondary)
    final_color = final_color + color * fill_diff * fill_intensity * fill_color;

    // Add ground bounce for underground visibility
    final_color = final_color + color * ground_bounce * ground_bounce_color;

    // Add rim highlight
    final_color = final_color + color * rim;

    return final_color;
}

// Silhouette mode lighting - minimal computation, single color output
// Used for very distant objects (>= 200 units) to reduce GPU workload
// Returns a flat color with subtle depth variation for visual coherence
fn calculate_silhouette_lighting(color: vec3<f32>, distance: f32) -> vec3<f32> {
    // Simple depth-based darkening for distant silhouettes
    // No normal calculation needed - just use base color with distance falloff
    let depth_factor = clamp(1.0 - (distance - LOD_SILHOUETTE_DISTANCE) * 0.002, 0.3, 0.8);
    return color * depth_factor;
}

// ============================================================================
// VERTEX SHADER
// ============================================================================

struct VertexOutput {
    @builtin(position) position: vec4<f32>,
    @location(0) uv: vec2<f32>,
}

@vertex
fn vs_main(@builtin(vertex_index) vertex_index: u32) -> VertexOutput {
    // Fullscreen triangle
    var positions = array<vec2<f32>, 3>(
        vec2<f32>(-1.0, -1.0),
        vec2<f32>(3.0, -1.0),
        vec2<f32>(-1.0, 3.0)
    );

    var output: VertexOutput;
    output.position = vec4<f32>(positions[vertex_index], 0.0, 1.0);
    output.uv = positions[vertex_index] * 0.5 + 0.5;
    output.uv.y = 1.0 - output.uv.y;  // Flip Y for screen coords
    return output;
}

// ============================================================================
// FRAGMENT SHADER
// ============================================================================

fn get_ray_direction(uv: vec2<f32>) -> vec3<f32> {
    // Convert UV [0,1] to NDC [-1,1]
    // UV.y was flipped in vertex shader, so we need to un-flip for clip space
    // Clip space: (-1,-1) is bottom-left, (1,1) is top-right
    let ndc_x = uv.x * 2.0 - 1.0;
    let ndc_y = 1.0 - uv.y * 2.0;  // Un-flip Y for correct clip space mapping

    // Use two points on the ray (near and far planes) to compute direction
    // glam::perspective_rh uses standard OpenGL depth: near=-1, far=+1 (NOT reverse-Z)
    let near_clip = vec4<f32>(ndc_x, ndc_y, -1.0, 1.0);
    let far_clip = vec4<f32>(ndc_x, ndc_y, 1.0, 1.0);

    // Transform both points from clip space to world space
    let near_world_h = uniforms.inv_view_proj * near_clip;
    let far_world_h = uniforms.inv_view_proj * far_clip;

    // Perspective divide
    let near_world = near_world_h.xyz / near_world_h.w;
    let far_world = far_world_h.xyz / far_world_h.w;

    // Ray direction is from near to far
    return normalize(far_world - near_world);
}

// Selection highlight color (bright cyan/teal)
const SELECTION_COLOR: vec3<f32> = vec3<f32>(0.2, 0.8, 1.0);
const SELECTION_OUTLINE_THICKNESS: f32 = 0.015;
const SELECTION_GLOW_INTENSITY: f32 = 0.4;

@fragment
fn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {
    let uv = input.uv;

    // ========================================================================
    // DEBUG MODE 2: Bypass all SDF rendering, output diagnostic colors
    // Use this to verify the shader pipeline and surface presentation work
    // ========================================================================
    if (uniforms.lod_debug_mode == 2u) {
        // Quadrant-based coloring for visibility testing
        // Red = top-left, Green = top-right, Blue = bottom-left, Yellow = bottom-right
        var debug_color = vec3<f32>(0.0, 0.0, 0.0);
        if (uv.x < 0.5 && uv.y < 0.5) {
            debug_color = vec3<f32>(1.0, 0.0, 0.0); // Red - top-left
        } else if (uv.x >= 0.5 && uv.y < 0.5) {
            debug_color = vec3<f32>(0.0, 1.0, 0.0); // Green - top-right
        } else if (uv.x < 0.5 && uv.y >= 0.5) {
            debug_color = vec3<f32>(0.0, 0.0, 1.0); // Blue - bottom-left
        } else {
            debug_color = vec3<f32>(1.0, 1.0, 0.0); // Yellow - bottom-right
        }
        // Overlay entity count visualization: white tint shows entities reached GPU
        // Each entity adds 5% brightness (max 50% for 10+ entities)
        let entity_tint = f32(min(entity_buffer.count, 10u)) * 0.05;
        debug_color = debug_color + vec3<f32>(entity_tint);
        return vec4<f32>(debug_color, 1.0);
    }

    // ========================================================================
    // DEBUG MODE 3: Solid color ray march test (US-0C05)
    // Tests ray marching with hardcoded sphere at origin + solid color output
    // If solid color visible - SDF/lighting is the issue
    // If solid color NOT visible - pipeline/present is the issue
    // ========================================================================
    if (uniforms.lod_debug_mode == 3u) {
        let ray_origin = uniforms.camera_pos;
        let ray_dir = get_ray_direction(uv);

        // Simple ray march against a hardcoded sphere at origin with radius 2.0
        var t: f32 = 0.0;
        let max_steps = 64u;
        let sphere_radius = 2.0;

        for (var i: u32 = 0u; i < max_steps; i = i + 1u) {
            let p = ray_origin + ray_dir * t;
            // Simple sphere SDF at origin
            let d = length(p) - sphere_radius;

            if (d < SURFACE_DIST) {
                // HIT: Return bright magenta for visibility
                return vec4<f32>(1.0, 0.0, 1.0, 1.0);
            }

            if (t > MAX_DIST) {
                break;
            }

            t = t + d;
        }

        // MISS: Return dark gray background
        return vec4<f32>(0.1, 0.1, 0.1, 1.0);
    }

    // ========================================================================
    // DEBUG MODE 4: Test scene SDF with solid color output (US-0C05)
    // Uses the actual scene_sdf() but returns solid color on hit
    // This tests the entity buffer and SDF evaluation without lighting complexity
    // ========================================================================
    if (uniforms.lod_debug_mode == 4u) {
        let ray_origin = uniforms.camera_pos;
        let ray_dir = get_ray_direction(uv);

        // Ray march using the actual scene SDF
        let result = ray_march(ray_origin, ray_dir, uniforms.step_count);

        if (result.hit) {
            // HIT: Return bright cyan for visibility (different from mode 3)
            return vec4<f32>(0.0, 1.0, 1.0, 1.0);
        }

        // MISS: Return dark gray background
        return vec4<f32>(0.1, 0.1, 0.1, 1.0);
    }

    // ========================================================================
    // DEBUG MODE 5: Visualize ray directions (US-0C05)
    // Tests if ray direction calculation is correct
    // R = positive X component, G = positive Y component, B = positive Z component
    // ========================================================================
    if (uniforms.lod_debug_mode == 5u) {
        let ray_origin = uniforms.camera_pos;
        let ray_dir = get_ray_direction(uv);

        // Visualize ray direction as RGB
        let debug_color = ray_dir * 0.5 + 0.5; // Map -1..1 to 0..1
        return vec4<f32>(debug_color, 1.0);
    }

    // ========================================================================
    // DEBUG MODE 6: Uniform Buffer Verification (US-0G05)
    // Visualizes uniform values directly to verify GPU buffer updates:
    // - Left column: Camera position (R=X, G=Y, B=Z normalized)
    // - Middle column: Resolution verification (gradient based on pixel coords)
    // - Right column: Step count visualization + time pulse
    // If you see correct gradients/colors, uniforms are reaching the GPU correctly
    // ========================================================================
    if (uniforms.lod_debug_mode == 6u) {
        var out_color = vec3<f32>(0.0, 0.0, 0.0);

        // Divide screen into thirds vertically
        let third = 1.0 / 3.0;

        if (uv.x < third) {
            // LEFT COLUMN: Camera position visualization
            // Map camera_pos components to color channels
            // Assuming reasonable camera range of -50 to 50 for each axis
            let cam_x = clamp((uniforms.camera_pos.x + 50.0) / 100.0, 0.0, 1.0);
            let cam_y = clamp((uniforms.camera_pos.y + 50.0) / 100.0, 0.0, 1.0);
            let cam_z = clamp((uniforms.camera_pos.z + 50.0) / 100.0, 0.0, 1.0);

            // Top region shows X position (red gradient)
            // Middle region shows Y position (green gradient)
            // Bottom region shows Z position (blue gradient)
            if (uv.y < 0.33) {
                // Z position - blue
                out_color = vec3<f32>(0.0, 0.0, cam_z);
                // Add stripe pattern to show Z value numerically
                let stripe = step(0.5, fract(uniforms.camera_pos.z * 0.2 + uv.y * 10.0));
                out_color = out_color + vec3<f32>(stripe * 0.2);
            } else if (uv.y < 0.66) {
                // Y position - green
                out_color = vec3<f32>(0.0, cam_y, 0.0);
                let stripe = step(0.5, fract(uniforms.camera_pos.y * 0.2 + uv.y * 10.0));
                out_color = out_color + vec3<f32>(stripe * 0.2);
            } else {
                // X position - red
                out_color = vec3<f32>(cam_x, 0.0, 0.0);
                let stripe = step(0.5, fract(uniforms.camera_pos.x * 0.2 + uv.y * 10.0));
                out_color = out_color + vec3<f32>(stripe * 0.2);
            }

            // Warn if camera is at origin (0,0,0) - bright magenta warning
            let cam_at_origin = abs(uniforms.camera_pos.x) < 0.001
                             && abs(uniforms.camera_pos.y) < 0.001
                             && abs(uniforms.camera_pos.z) < 0.001;
            if (cam_at_origin) {
                out_color = vec3<f32>(1.0, 0.0, 1.0); // Magenta warning
            }

        } else if (uv.x < 2.0 * third) {
            // MIDDLE COLUMN: Resolution verification
            // Creates a gradient that should match pixel coords exactly
            // If resolution is wrong, this will look distorted

            // Expected pixel coordinates
            let expected_x = uv.x * uniforms.resolution.x;
            let expected_y = uv.y * uniforms.resolution.y;

            // Create checkerboard pattern based on actual pixel coords
            // Each square is 32 pixels wide
            let checker_x = step(0.5, fract(expected_x / 32.0));
            let checker_y = step(0.5, fract(expected_y / 32.0));
            let checker = abs(checker_x - checker_y);

            // Color based on which quadrant we're in
            let in_right = f32(uv.x > 0.5);
            let in_bottom = f32(uv.y > 0.5);

            out_color = vec3<f32>(
                checker * 0.3 + in_right * 0.4,
                checker * 0.3 + in_bottom * 0.4,
                0.2
            );

            // Add resolution text hint: brightness shows if resolution is reasonable
            // Bright = good resolution (800-2000), dim = too small or too large
            let res_quality = clamp(
                min(uniforms.resolution.x, uniforms.resolution.y) / 1000.0,
                0.2,
                1.0
            );
            out_color = out_color * res_quality;

        } else {
            // RIGHT COLUMN: Step count and time verification
            // Top: step count visualization (horizontal bars)
            // Bottom: time-based animation (proves uniforms update each frame)

            if (uv.y > 0.5) {
                // Step count visualization
                // Map step_count (typical range 32-256) to visual bars
                let normalized_steps = clamp(f32(uniforms.step_count) / 256.0, 0.0, 1.0);

                // Create horizontal bar that fills based on step count
                let bar_fill = f32(uv.y - 0.5) * 2.0; // 0-1 in this region
                if (bar_fill < normalized_steps) {
                    // Gradient from red (low) to green (high step count)
                    out_color = vec3<f32>(
                        1.0 - normalized_steps,
                        normalized_steps,
                        0.2
                    );
                } else {
                    out_color = vec3<f32>(0.1, 0.1, 0.1); // Empty bar background
                }

                // If step_count is 0, show warning
                if (uniforms.step_count == 0u) {
                    out_color = vec3<f32>(1.0, 0.0, 0.0); // Red warning
                }

            } else {
                // Time-based animation (proves uniforms update)
                // Cycles through colors based on time
                let time_phase = uniforms.time * 0.5;
                let r = sin(time_phase) * 0.5 + 0.5;
                let g = sin(time_phase + 2.094) * 0.5 + 0.5; // +2π/3
                let b = sin(time_phase + 4.189) * 0.5 + 0.5; // +4π/3

                out_color = vec3<f32>(r, g, b);

                // Add pulsing ring to show time updates
                let ring_center = vec2<f32>(0.833, 0.25); // Center of this region
                let dist_to_center = length(uv - ring_center);
                let ring_radius = 0.1 + sin(uniforms.time * 3.0) * 0.05;
                let ring = smoothstep(ring_radius - 0.02, ring_radius, dist_to_center)
                         - smoothstep(ring_radius, ring_radius + 0.02, dist_to_center);
                out_color = out_color + vec3<f32>(ring * 0.5);
            }
        }

        return vec4<f32>(out_color, 1.0);
    }

    // ========================================================================
    // DEBUG MODE 7: Simple Clear Color Only (US-0K04)
    // Renders only a solid color without any shader processing.
    // This is the most minimal debug mode to verify:
    // - Surface/texture copy to iced works
    // - Shader output is visible on screen
    // - No shader code path issues
    // If you see solid bright lime green, the texture copy to iced surface works.
    // If you see nothing/black, there's an issue with surface presentation.
    // ========================================================================
    if (uniforms.lod_debug_mode == 7u) {
        // Return a very distinctive bright lime green color
        // This is intentionally chosen to be visible and unmistakable
        return vec4<f32>(0.2, 1.0, 0.2, 1.0);
    }

    // ========================================================================
    // ENTITY DEBUG MODE 1: Entity Position as RGB Color (US-0M04)
    // Renders entity positions as colors to verify entity data reaches the shader.
    // R = X position, G = Y position, B = Z position (normalized to view range)
    // Press F9 to cycle through entity debug modes.
    // ========================================================================
    if (uniforms.entity_debug_mode == 1u) {
        let ray_origin = uniforms.camera_pos;
        let ray_dir = get_ray_direction(uv);
        let result = ray_march(ray_origin, ray_dir, uniforms.step_count);

        if (result.hit && result.entity_index >= 0) {
            let entity = entity_buffer.entities[u32(result.entity_index)];
            let entity_pos = get_entity_position(entity);

            // Normalize position to 0-1 range for visualization
            // Assumes entities are within -10 to 10 range for each axis
            let normalized_pos = (entity_pos + vec3<f32>(10.0)) / 20.0;
            let clamped_pos = clamp(normalized_pos, vec3<f32>(0.0), vec3<f32>(1.0));

            // Log first entity data (only for pixel near center to avoid spam)
            // This creates a visible "marker" in the center showing debug info
            let center_dist = length(uv - vec2<f32>(0.5, 0.5));
            if (center_dist < 0.02) {
                // Center marker: show white to indicate entity was hit
                return vec4<f32>(1.0, 1.0, 1.0, 1.0);
            }

            // Return position as RGB color
            return vec4<f32>(clamped_pos, 1.0);
        }

        // No entity hit - show dark background
        return vec4<f32>(0.1, 0.1, 0.15, 1.0);
    }

    // ========================================================================
    // ENTITY DEBUG MODE 2: Entity Count as Brightness (US-0M04)
    // Renders brightness based on entity count to verify entity buffer count.
    // More entities = brighter color.
    // Also shows entity count visually in the corner.
    // ========================================================================
    if (uniforms.entity_debug_mode == 2u) {
        let count = entity_buffer.count;

        // Normalize count to brightness (0-10 entities = 0-1 brightness)
        let brightness = clamp(f32(count) / 10.0, 0.0, 1.0);

        // Base color based on entity count
        var base_color = vec3<f32>(brightness * 0.5, brightness * 0.8, brightness);

        // Add visual indicator bars for entity count (each bar = 1 entity)
        // Displayed at bottom of screen
        if (uv.y > 0.95) {
            let bar_index = u32(uv.x * 20.0); // 20 possible bars
            if (bar_index < count) {
                // Entity bar - bright cyan
                base_color = vec3<f32>(0.2, 1.0, 1.0);
            } else {
                // Empty slot - dark
                base_color = vec3<f32>(0.1, 0.1, 0.1);
            }
        }

        // Show ray march result with count-based tinting
        let ray_origin = uniforms.camera_pos;
        let ray_dir = get_ray_direction(uv);
        let result = ray_march(ray_origin, ray_dir, uniforms.step_count);

        if (result.hit && uv.y <= 0.95) {
            // Hit an entity - show count-tinted white
            let hit_brightness = 0.5 + brightness * 0.5;
            return vec4<f32>(hit_brightness, hit_brightness, hit_brightness, 1.0);
        }

        return vec4<f32>(base_color, 1.0);
    }

    // Get ray from camera
    let ray_origin = uniforms.camera_pos;
    let ray_dir = get_ray_direction(uv);

    // Use step count from uniforms (configurable quality)
    let max_steps = uniforms.step_count;

    // Ray march the scene
    let result = ray_march(ray_origin, ray_dir, max_steps);

    // Background color (bg-deep from visual design, converted to linear)
    let bg_color = vec3<f32>(0.05, 0.05, 0.06);

    if (!result.hit) {
        // Gradient sky for visual interest
        let sky_gradient = mix(bg_color, vec3<f32>(0.08, 0.08, 0.12), uv.y);
        return vec4<f32>(sky_gradient, 1.0);
    }

    // Get surface color based on hit type (terrain, entity, or preview)
    var surface_color = vec3<f32>(0.7, 0.7, 0.7);
    var is_selected = 0.0;
    var lod_octaves = result.lod_octaves;
    var is_preview_hit = result.is_preview;

    if (result.is_preview) {
        // Preview object: use the preview ghost color
        surface_color = PREVIEW_COLOR;
    } else if (result.is_hands) {
        // US-019: First-person hands - use skin tone color matching player body
        surface_color = FP_HAND_COLOR;
    } else if (result.is_marker) {
        // Distance reference marker trees - color-coded by distance
        // Trunk is brown, foliage is green with distance-based tint
        let hit_height = result.position.y;
        let is_trunk = hit_height < result.marker_distance * 0.02;  // Lower part is trunk

        if (is_trunk) {
            // Brown trunk color
            surface_color = vec3<f32>(0.4, 0.25, 0.1);
        } else {
            // Foliage color varies by distance marker:
            // 10m = bright green, 25m = yellow-green, 50m = yellow, 100m = orange, 1000m = red
            if (result.marker_distance < 15.0) {
                // 10m marker - bright green
                surface_color = vec3<f32>(0.2, 0.8, 0.2);
            } else if (result.marker_distance < 30.0) {
                // 25m marker - yellow-green
                surface_color = vec3<f32>(0.5, 0.8, 0.2);
            } else if (result.marker_distance < 75.0) {
                // 50m marker - yellow
                surface_color = vec3<f32>(0.8, 0.8, 0.2);
            } else if (result.marker_distance < 500.0) {
                // 100m marker - orange
                surface_color = vec3<f32>(0.9, 0.5, 0.1);
            } else {
                // 1000m marker - red (most distant, easy to spot)
                surface_color = vec3<f32>(0.9, 0.2, 0.2);
            }
        }
    } else if (result.is_terrain) {
        // Terrain coloring based on height
        let height = result.position.y;
        let height_factor = clamp((height + terrain_config.amplitude) / (terrain_config.amplitude * 2.0), 0.0, 1.0);
        surface_color = mix(TERRAIN_COLOR_LOW, TERRAIN_COLOR_HIGH, height_factor);
    } else if (result.entity_index >= 0) {
        let entity = entity_buffer.entities[u32(result.entity_index)];
        // Use helper function to get vec3 color from scalar fields
        surface_color = get_entity_color(entity);
        is_selected = entity.selected;
        lod_octaves = entity.lod_octaves;
    }
    // LOD octaves are available for use with FBM/noise functions:
    // - LOD_FULL_OCTAVES (8): Full detail for near objects (< 10 units)
    // - LOD_MEDIUM_OCTAVES (4): Medium detail (10-50 units)
    // - LOD_LOW_OCTAVES (2): Low detail (50-200 units)
    // - LOD_SILHOUETTE_OCTAVES (1): Minimal detail (>= 200 units)
    // Use fbm_lod(p, distance, base_octaves) for LOD-aware noise

    // Determine if we're in silhouette mode or transitioning to it
    let silhouette_blend_start = LOD_SILHOUETTE_DISTANCE - LOD_SILHOUETTE_BLEND_RANGE;
    let is_silhouette_distance = result.distance >= LOD_SILHOUETTE_DISTANCE;
    let is_blending_to_silhouette = result.distance >= silhouette_blend_start && result.distance < LOD_SILHOUETTE_DISTANCE;

    var final_lit_color: vec3<f32>;

    if (is_silhouette_distance) {
        // Full silhouette mode: single color, no normal calculation, minimal SDF ops
        final_lit_color = calculate_silhouette_lighting(surface_color, result.distance);
    } else if (is_blending_to_silhouette) {
        // Smooth blend between full lighting and silhouette mode
        // This prevents visual popping when transitioning
        let blend_factor = (result.distance - silhouette_blend_start) / LOD_SILHOUETTE_BLEND_RANGE;

        // Calculate full lighting
        let normal = calculate_normal(result.position);
        let full_lit_color = calculate_lighting(result.position, normal, surface_color);

        // Calculate silhouette color
        let silhouette_color = calculate_silhouette_lighting(surface_color, result.distance);

        // Smooth blend using smoothstep for gradual transition
        let smooth_blend = smoothstep(0.0, 1.0, blend_factor);
        final_lit_color = mix(full_lit_color, silhouette_color, smooth_blend);

        // Apply selection highlight if needed (with reduced intensity during blend)
        if (is_selected > 0.5) {
            let view_dir = normalize(uniforms.camera_pos - result.position);
            let fresnel = pow(1.0 - max(dot(view_dir, normal), 0.0), 2.5);
            let rim_glow = fresnel * SELECTION_GLOW_INTENSITY * (1.0 - smooth_blend);
            final_lit_color = mix(final_lit_color, final_lit_color + SELECTION_COLOR * rim_glow, 1.0);
            final_lit_color = mix(final_lit_color, final_lit_color * vec3<f32>(1.1, 1.2, 1.3), 0.15 * (1.0 - smooth_blend));
        }
    } else {
        // Full detail mode: calculate normal and apply full lighting
        let normal = calculate_normal(result.position);
        let lit_color = calculate_lighting(result.position, normal, surface_color);
        final_lit_color = lit_color;

        // Apply selection highlight effect
        if (is_selected > 0.5) {
            // Add rim lighting effect for selected objects
            let view_dir = normalize(uniforms.camera_pos - result.position);
            let fresnel = pow(1.0 - max(dot(view_dir, normal), 0.0), 2.5);
            let rim_glow = fresnel * SELECTION_GLOW_INTENSITY;

            // Blend selection color with surface
            final_lit_color = mix(lit_color, lit_color + SELECTION_COLOR * rim_glow, 1.0);

            // Add subtle overall tint to selected objects
            final_lit_color = mix(final_lit_color, final_lit_color * vec3<f32>(1.1, 1.2, 1.3), 0.15);
        }
    }

    // Apply simple fog for depth (0.0001 = good visibility for 10km spherical world)
    // fog_amount at 100m = 1%, 500m = 5%, 1000m = 10%, 2000m = 18%, 5000m = 39%
    // NOTE: 1 unit = 1 meter (SI units)
    // This allows the 1km distance marker trees to be clearly visible
    let fog_amount = 1.0 - exp(-result.distance * 0.0001);
    var final_color = mix(final_lit_color, bg_color, fog_amount);

    // LOD Debug Mode: Override color with LOD-based debug visualization
    if (uniforms.lod_debug_mode == 1u) {
        // Get LOD debug color based on distance from camera
        let lod_color = get_lod_debug_color(result.distance);
        // Apply lighting to the debug color to maintain some depth perception
        // Use a simplified lighting model with the debug color
        let normal = calculate_normal(result.position);
        let light_dir = normalize(vec3<f32>(0.5, 1.0, 0.3));
        let diff = max(dot(normal, light_dir), 0.0);
        let ambient = 0.3;
        let lit_lod_color = lod_color * (ambient + diff * 0.7);
        // Apply fog to debug color as well
        final_color = mix(lit_lod_color, bg_color, fog_amount * 0.5);
    }

    // Apply semi-transparency for preview objects
    // Blend with a pulsing glow effect for visibility
    if (is_preview_hit) {
        // Add pulsing glow effect based on time
        let pulse = 0.3 + 0.2 * sin(uniforms.time * 3.0);
        let glow_color = PREVIEW_COLOR * (1.0 + pulse);

        // Blend final color with background for semi-transparency
        // The preview appears as a ghostly overlay
        let preview_blend = PREVIEW_ALPHA + pulse * 0.1;
        final_color = mix(bg_color, glow_color, preview_blend);

        // Add edge glow effect using fresnel
        let normal = calculate_normal(result.position);
        let view_dir = normalize(uniforms.camera_pos - result.position);
        let fresnel = pow(1.0 - max(dot(view_dir, normal), 0.0), 2.0);
        final_color = final_color + PREVIEW_COLOR * fresnel * 0.5;
    }

    return vec4<f32>(final_color, 1.0);
}
